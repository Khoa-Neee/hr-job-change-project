{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Preprocessing\n",
    "\n",
    "Notebook này sẽ sử dụng các hàm từ `src/data_processing.py` để tiền xử lý dữ liệu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "from data_processing import (\n",
    "    load_csv_data,\n",
    "    get_missing_stats,\n",
    "    get_numeric_column,\n",
    "    get_target,\n",
    "    get_column_by_name,\n",
    "    process_experience_column,\n",
    "    get_categorical_stats\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dữ liệu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước dữ liệu: (19158, 14)\n",
      "Số mẫu: 19158, Số features: 14\n",
      "Các cột: ['enrollee_id', 'city', 'city_development_index', 'gender', 'relevent_experience', 'enrolled_university', 'education_level', 'major_discipline', 'experience', 'company_size', 'company_type', 'last_new_job', 'training_hours', 'target']\n"
     ]
    }
   ],
   "source": [
    "# Load dữ liệu train\n",
    "TRAIN_PATH = '../data/raw/aug_train.csv'\n",
    "data, header = load_csv_data(TRAIN_PATH)\n",
    "\n",
    "print(f\"Kích thước dữ liệu: {data.shape}\")\n",
    "print(f\"Số mẫu: {data.shape[0]}, Số features: {data.shape[1]}\")\n",
    "print(f\"Các cột: {header}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Xử lý Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Xử lý các cột Numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các cột numeric:\n",
      "city_development_index: mean=0.8288, std=0.1234, missing=0\n",
      "training_hours: mean=65.37, std=60.06, missing=0\n",
      "experience: mean=10.11, std=6.76, missing=65\n",
      "\n",
      "Experience sau khi impute (median=9.00): missing=0\n"
     ]
    }
   ],
   "source": [
    "# Xử lý các cột numeric\n",
    "cdi = get_numeric_column(data, header, 'city_development_index')\n",
    "training_hours = get_numeric_column(data, header, 'training_hours')\n",
    "\n",
    "# experience: có missing và giá trị đặc biệt (>20, <1, never)\n",
    "experience = get_numeric_column(data, header, 'experience', process_experience=True)\n",
    "\n",
    "print(\"Các cột numeric:\")\n",
    "print(f\"city_development_index: mean={np.nanmean(cdi):.4f}, std={np.nanstd(cdi):.4f}, missing={np.sum(np.isnan(cdi))}\")\n",
    "print(f\"training_hours: mean={np.nanmean(training_hours):.2f}, std={np.nanstd(training_hours):.2f}, missing={np.sum(np.isnan(training_hours))}\")\n",
    "print(f\"experience: mean={np.nanmean(experience):.2f}, std={np.nanstd(experience):.2f}, missing={np.sum(np.isnan(experience))}\")\n",
    "\n",
    "# Impute missing values cho experience bằng median\n",
    "experience_median = np.nanmedian(experience)\n",
    "experience_filled = experience.copy()\n",
    "experience_filled[np.isnan(experience_filled)] = experience_median\n",
    "print(f\"\\nExperience sau khi impute (median={experience_median:.2f}): missing={np.sum(np.isnan(experience_filled))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Xử lý các cột Categorical - One-hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevent_experience      : 2 categories, missing được thay bằng 'Missing'\n",
      "enrolled_university      : 4 categories, missing được thay bằng 'Missing'\n",
      "education_level          : 6 categories, missing được thay bằng 'Missing'\n",
      "last_new_job             : 7 categories, missing được thay bằng 'Missing'\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(data, header, colname, fill_missing='Missing'):\n",
    "    \"\"\"\n",
    "    One-hot encode cho một cột categorical\n",
    "    \"\"\"\n",
    "    col = get_column_by_name(data, header, colname)\n",
    "    col_filled = col.copy()\n",
    "    \n",
    "    # Thay missing bằng giá trị fill_missing\n",
    "    col_filled[col_filled == ''] = fill_missing\n",
    "    \n",
    "    # Lấy unique categories\n",
    "    categories = np.unique(col_filled)\n",
    "    \n",
    "    # Tạo one-hot encoding\n",
    "    n_samples = len(col_filled)\n",
    "    n_categories = len(categories)\n",
    "    encoded = np.zeros((n_samples, n_categories), dtype=int)\n",
    "    \n",
    "    for i, category in enumerate(categories):\n",
    "        encoded[col_filled == category, i] = 1\n",
    "    \n",
    "    return encoded, categories.tolist()\n",
    "\n",
    "\n",
    "# Danh sách các cột categorical cần encode.\n",
    "# Bỏ các feature ,'gender', 'company_type', 'company_size','major_discipline'. Vì có sự áp đảo của 1 dữ liệu so với các dữ liệu khác\n",
    "\n",
    "categorical_cols = [\n",
    "    'relevent_experience', 'enrolled_university', \n",
    "    'education_level',\n",
    "    'last_new_job'\n",
    "]\n",
    "\n",
    "# One-hot encode từng cột\n",
    "encoded_features = {}\n",
    "all_categories = {}\n",
    "\n",
    "for colname in categorical_cols:\n",
    "    encoded, categories = one_hot_encode(data, header, colname)\n",
    "    encoded_features[colname] = encoded\n",
    "    all_categories[colname] = categories\n",
    "    print(f\"{colname:25s}: {encoded.shape[1]} categories, missing được thay bằng 'Missing'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Xử lý cột city - Label Encoding (vì có quá nhiều city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city: 123 unique values, encoded thành label 0-122\n"
     ]
    }
   ],
   "source": [
    "def label_encode(data, header, colname):\n",
    "    \"\"\"\n",
    "    Label encode cho một cột (chuyển string thành số)\n",
    "    \"\"\"\n",
    "    col = get_column_by_name(data, header, colname)\n",
    "    unique_vals = np.unique(col)\n",
    "    \n",
    "    # Tạo mapping\n",
    "    label_map = {val: i for i, val in enumerate(unique_vals)}\n",
    "    \n",
    "    # Encode\n",
    "    encoded = np.array([label_map[val] for val in col], dtype=int)\n",
    "    \n",
    "    return encoded, label_map\n",
    "\n",
    "\n",
    "# Label encode cho city (vì có quá nhiều city để one-hot)\n",
    "city_encoded, city_label_map = label_encode(data, header, 'city')\n",
    "print(f\"city: {len(city_label_map)} unique values, encoded thành label 0-{len(city_label_map)-1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kết hợp tất cả features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base numeric features: CDI, Training_hours, Experience, City\n",
      "\n",
      "Tạo Interaction Features...\n",
      "  - CDI * Experience\n",
      "\n",
      "Tạo Polynomial Features (bậc 2)...\n",
      "  - CDI^2\n",
      "  - Experience^2\n",
      "\n",
      "Tạo Ratio Features...\n",
      "  - Training_hours / (Experience + 1)\n",
      "  - CDI / (Experience + 1)\n",
      "\n",
      "Tạo Log Transform Features...\n",
      "  - Log(Experience + 1)\n",
      "  - Log(Training_hours + 1)\n",
      "\n",
      "Thêm Categorical Features (one-hot)...\n",
      "  - relevent_experience (2 categories)\n",
      "  - enrolled_university (4 categories)\n",
      "  - education_level (6 categories)\n",
      "  - last_new_job (7 categories)\n",
      "\n",
      "============================================================\n",
      "Shape của X: (19158, 30)\n",
      "Số features: 30 (base: 4, engineered: 7, categorical: 19)\n",
      "============================================================\n",
      "\n",
      "Shape của y: (19158,)\n",
      "Phân phối target: [14381  4777]\n"
     ]
    }
   ],
   "source": [
    "# Tạo danh sách các feature arrays\n",
    "feature_list = []\n",
    "\n",
    "# 1. Numeric features (base features)\n",
    "feature_list.append(cdi.reshape(-1, 1))  # city_development_index\n",
    "feature_list.append(training_hours.reshape(-1, 1))  # training_hours\n",
    "feature_list.append(experience_filled.reshape(-1, 1))  # experience (đã impute)\n",
    "feature_list.append(city_encoded.reshape(-1, 1))  # city (label encoded)\n",
    "\n",
    "print(\"Base numeric features: CDI, Training_hours, Experience, City\")\n",
    "\n",
    "# 2. Feature Engineering: Interaction và Polynomial Features\n",
    "# Dựa trên phân tích tương quan:\n",
    "# - CDI và Target: -0.34 (tương quan mạnh)\n",
    "\n",
    "# 2.1. Interaction features (tương quan giữa các biến)\n",
    "print(\"\\nTạo Interaction Features...\")\n",
    "# CDI * Experience (vì có tương quan 0.33)\n",
    "cdi_exp_interaction = (cdi * experience_filled).reshape(-1, 1)\n",
    "feature_list.append(cdi_exp_interaction)\n",
    "print(\"  - CDI * Experience\")\n",
    "\n",
    "# 2.2. Polynomial features (bậc 2 cho các biến quan trọng)\n",
    "print(\"\\nTạo Polynomial Features (bậc 2)...\")\n",
    "# CDI^2 (vì CDI tương quan mạnh với target)\n",
    "cdi_squared = (cdi ** 2).reshape(-1, 1)\n",
    "feature_list.append(cdi_squared)\n",
    "print(\"  - CDI^2\")\n",
    "\n",
    "# Experience^2\n",
    "exp_squared = (experience_filled ** 2).reshape(-1, 1)\n",
    "feature_list.append(exp_squared)\n",
    "print(\"  - Experience^2\")\n",
    "\n",
    "# 2.3. Ratio features (tỷ lệ giữa các biến)\n",
    "print(\"\\nTạo Ratio Features...\")\n",
    "# Training_hours / (Experience + 1) - để tránh chia cho 0\n",
    "training_per_exp = (training_hours / (experience_filled + 1)).reshape(-1, 1)\n",
    "feature_list.append(training_per_exp)\n",
    "print(\"  - Training_hours / (Experience + 1)\")\n",
    "\n",
    "# CDI / (Experience + 1)\n",
    "cdi_per_exp = (cdi / (experience_filled + 1)).reshape(-1, 1)\n",
    "feature_list.append(cdi_per_exp)\n",
    "print(\"  - CDI / (Experience + 1)\")\n",
    "\n",
    "# 2.4. Log transform cho các biến có phân phối lệch\n",
    "print(\"\\nTạo Log Transform Features...\")\n",
    "# Log(Experience + 1)\n",
    "exp_log = np.log1p(experience_filled).reshape(-1, 1)\n",
    "feature_list.append(exp_log)\n",
    "print(\"  - Log(Experience + 1)\")\n",
    "\n",
    "# Log(Training_hours + 1)\n",
    "training_log = np.log1p(training_hours).reshape(-1, 1)\n",
    "feature_list.append(training_log)\n",
    "print(\"  - Log(Training_hours + 1)\")\n",
    "\n",
    "# 3. Categorical features (one-hot encoded)\n",
    "print(\"\\nThêm Categorical Features (one-hot)...\")\n",
    "for colname in categorical_cols:\n",
    "    feature_list.append(encoded_features[colname])\n",
    "    print(f\"  - {colname} ({encoded_features[colname].shape[1]} categories)\")\n",
    "\n",
    "# Kết hợp tất cả features\n",
    "X = np.hstack(feature_list)\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"Shape của X: {X.shape}\")\n",
    "print(f\"Số features: {X.shape[1]} (base: 4, engineered: {X.shape[1] - 4 - sum([encoded_features[col].shape[1] for col in categorical_cols])}, categorical: {sum([encoded_features[col].shape[1] for col in categorical_cols])})\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get target\n",
    "y = get_target(data, header)\n",
    "print(f\"\\nShape của y: {y.shape}\")\n",
    "print(f\"Phân phối target: {np.bincount(y)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering - Tạo thêm features từ tương quan\n",
    "\n",
    "Đã thêm các interaction và polynomial features dựa trên phân tích tương quan:\n",
    "- CDI và Experience có tương quan 0.33 → Tạo CDI * Experience\n",
    "- CDI và Target có tương quan -0.34 → Tạo CDI^2\n",
    "- Các ratio và log transform features\n",
    "\n",
    "## 5. Normalization - Chuẩn hóa features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_normalized shape: (19158, 30)\n",
      "Mean sau normalization: [-6.61351404e-14 -9.02874764e-17 -3.07359896e-16  3.29381231e-16\n",
      " -4.76675455e-14]\n",
      "Std sau normalization: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def normalize_features(X, method='standard'):\n",
    "    if method == 'standard':\n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0)\n",
    "        # Tránh chia cho 0\n",
    "        std[std == 0] = 1\n",
    "        X_norm = (X - mean) / std\n",
    "        return X_norm, mean, std, None, None\n",
    "    \n",
    "    elif method == 'minmax':\n",
    "        min_vals = np.min(X, axis=0)\n",
    "        max_vals = np.max(X, axis=0)\n",
    "        # Tránh chia cho 0\n",
    "        range_vals = max_vals - min_vals\n",
    "        range_vals[range_vals == 0] = 1\n",
    "        X_norm = (X - min_vals) / range_vals\n",
    "        return X_norm, None, None, min_vals, max_vals\n",
    "\n",
    "\n",
    "# Chuẩn hóa bằng StandardScaler (z-score normalization)\n",
    "X_normalized, X_mean, X_std, _, _ = normalize_features(X, method='standard')\n",
    "\n",
    "print(f\"X_normalized shape: {X_normalized.shape}\")\n",
    "print(f\"Mean sau normalization: {np.mean(X_normalized, axis=0)[:5]}\")  # Hiển thị 5 features đầu\n",
    "print(f\"Std sau normalization: {np.std(X_normalized, axis=0)[:5]}\")  # Hiển thị 5 features đầu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Thêm bias term (intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_final shape (sau khi thêm bias): (19158, 31)\n",
      "Features: 31 (1 bias + 30 features)\n"
     ]
    }
   ],
   "source": [
    "# Thêm cột bias (toàn bộ là 1) vào đầu feature matrix\n",
    "n_samples = X_normalized.shape[0]\n",
    "bias = np.ones((n_samples, 1))\n",
    "X_final = np.hstack([bias, X_normalized])\n",
    "\n",
    "print(f\"X_final shape (sau khi thêm bias): {X_final.shape}\")\n",
    "print(f\"Features: {X_final.shape[1]} (1 bias + {X_normalized.shape[1]} features)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lưu dữ liệu đã preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ĐÃ LƯU DỮ LIỆU SAU STRATIFIED SPLIT:\n",
      "============================================================\n",
      "\n",
      "Train/Test split (từ aug_train.csv ban đầu):\n",
      "  - Test size: 20.0% (stratified)\n",
      "  - X_train.npy: (15327, 31)\n",
      "  - y_train.npy: (15327,) | Phân phối: [11505  3822]\n",
      "  - X_test.npy : (3831, 31)\n",
      "  - y_test.npy : (3831,) | Phân phối: [2876  955]\n",
      "\n",
      "Preprocessing info:\n",
      "  - preprocessing_info.pkl\n",
      "\n",
      "============================================================\n",
      "Tổng kết cuối cùng:\n",
      "  - Tổng mẫu ban đầu: 19,158\n",
      "  - Train: 15,327 mẫu\n",
      "  - Test : 3,831 mẫu\n",
      "  - Features mỗi mẫu: 31\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Lưu dữ liệu đã preprocess với stratified train/test split\n",
    "# Thiết lập test_size\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Stratified split (tỷ lệ giữ nguyên giữa các class)\n",
    "class0_idx = np.where(y == 0)[0]\n",
    "class1_idx = np.where(y == 1)[0]\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "rng.shuffle(class0_idx)\n",
    "rng.shuffle(class1_idx)\n",
    "\n",
    "n_class0_test = int(len(class0_idx) * TEST_SIZE)\n",
    "n_class1_test = int(len(class1_idx) * TEST_SIZE)\n",
    "\n",
    "test_idx = np.concatenate([class0_idx[:n_class0_test], class1_idx[:n_class1_test]])\n",
    "train_idx = np.concatenate([class0_idx[n_class0_test:], class1_idx[n_class1_test:]])\n",
    "\n",
    "# Shuffle final indices to avoid ordering by class\n",
    "rng.shuffle(train_idx)\n",
    "rng.shuffle(test_idx)\n",
    "\n",
    "X_train_split = X_final[train_idx]\n",
    "y_train_split = y[train_idx]\n",
    "X_test_split = X_final[test_idx]\n",
    "y_test_split = y[test_idx]\n",
    "\n",
    "# Lưu train/test sau split\n",
    "np.save('../data/processed/X_train.npy', X_train_split)\n",
    "np.save('../data/processed/y_train.npy', y_train_split)\n",
    "np.save('../data/processed/X_test.npy', X_test_split)\n",
    "np.save('../data/processed/y_test.npy', y_test_split)\n",
    "\n",
    "# Lưu thêm các thông tin cần thiết cho preprocessing\n",
    "import pickle\n",
    "preprocessing_info = {\n",
    "    'experience_median': experience_median,\n",
    "    'city_label_map': city_label_map,\n",
    "    'all_categories': all_categories,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'test_size': TEST_SIZE,\n",
    "    'random_seed': RANDOM_SEED\n",
    "}\n",
    "with open('../data/processed/preprocessing_info.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessing_info, f)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ĐÃ LƯU DỮ LIỆU SAU STRATIFIED SPLIT:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTrain/Test split (từ aug_train.csv ban đầu):\")\n",
    "print(f\"  - Test size: {TEST_SIZE*100:.1f}% (stratified)\")\n",
    "print(f\"  - X_train.npy: {X_train_split.shape}\")\n",
    "print(f\"  - y_train.npy: {y_train_split.shape} | Phân phối: {np.bincount(y_train_split)}\")\n",
    "print(f\"  - X_test.npy : {X_test_split.shape}\")\n",
    "print(f\"  - y_test.npy : {y_test_split.shape} | Phân phối: {np.bincount(y_test_split)}\")\n",
    "\n",
    "print(\"\\nPreprocessing info:\")\n",
    "print(\"  - preprocessing_info.pkl\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"Tổng kết cuối cùng:\")\n",
    "print(f\"  - Tổng mẫu ban đầu: {X_final.shape[0]:,}\")\n",
    "print(f\"  - Train: {X_train_split.shape[0]:,} mẫu\")\n",
    "print(f\"  - Test : {X_test_split.shape[0]:,} mẫu\")\n",
    "print(f\"  - Features mỗi mẫu: {X_final.shape[1]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
